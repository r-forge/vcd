\documentclass[10pt]{article}
\usepackage{dsc2003}
\usepackage{Sweave, graphicx}
\usepackage{Z}

\setlength{\parskip}{0.5ex plus0.1ex minus0.1ex}
\setlength{\parindent}{0em}

\bibpunct{(}{)}{;}{a}{}{,}

\begin{document}

\SweaveOpts{engine=R}
\setkeys{Gin}{width=0.8\textwidth}

<<preliminaries,echo=FALSE,results=hide>>=
set.seed(12345)
library(vcd)
data(Bundesliga)
goals <- xtabs(~ AwayGoals + HomeGoals, data = Bundesliga, subset = Year == 1995)
data(HairEyeColor)
haireye <- xtabs(Freq ~ Hair + Eye, data = as.data.frame(HairEyeColor), subset = Sex == "Female")
data(UCBAdmissions)
@


\title{Visualizing Independence Using Extended Association Plots}
\author{\hfill David Meyer$^\dag$ \hfill Achim Zeileis$^\dag$ \hfill Kurt Hornik$^\ddag$ \hfill \hfill \\[0.2cm]
\dag {\it \small Institut f\"ur Statistik \& Wahrscheinlichkeitstheorie,
 Technische Universit\"at Wien}\\
\ddag {\it \small Institut f\"ur Statistik, Wirtschaftsuniversit\"at Wien}
}
\date{}
\maketitle

\begin{abstract}
Association plots---a visualization technique for the independence problem in 2-way
contingency tables---are extended in three directions:
\begin{enumerate}
 \item The visualization is enhanced by using colors for the
  importance of the residuals.
 \item Two extensions for the use of multi-way tables are proposed.
 \item The implementation in the \textsf{R} system is improved using a more modular
  design and allowing a more flexible specification of plotting parameters.
\end{enumerate}
\end{abstract}

\section{Introduction} \label{sec:introduction}

Given two categorical variables, or, equivalently, their contingency
table, one is often interested in investigating whether they are 
independent or not. Usually, the $\chi^2$ test statistic---the sum of the
squared Pearson residuals---is used as a measure of association.
Now, whenever the statistic is
significant, one might ask for a more detailed analysis on the basis
of the residuals themselves.
This task can greatly be sustained by the use of graphical
methods such as the association plot, for which we propose some
extensions: the use of colors for the shading of the residuals, two
possible extensions for multi-way tables, and a new, more flexible
implementation using {\sf R}'s alternative graphical system,
\texttt{grid}. The new functionality is provided by the {\sf R} package
\texttt{vcd}, inspired by the book `Visualizing Categorical Data'
\citep{vcd:Friendly:2000}.

\section{Association plots for 2-way tables} \label{sec:assocplots}

To assess independence of 2 categorical variables, usually
a 2-way contingency table is considered with cell frequencies $\{n_{ij}\}$ for
$i = 1, \dots, I$ and $j = 1, \dots, J$ and row and column sums
$n_{i+} = \sum_i n_{ij}$ and $n_{+j} = \sum_j n_{ij}$ respectively. For
convenience, the number of observations is denoted $n = n_{++}$.

Given an underlying distribution with theoretical cell probabilities
$\pi_{ij}$, the null hypothesis of independence of the two categorical
variables can be formulated as
\begin{equation} \label{eq:H0}
H_0: \; \pi_{ij} \quad = \quad \pi_{i+} \pi_{+j}.
\end{equation}

The expected cell frequencies in this model are
$\hat n_{ij} = n_{i+}n_{+j}/n$. The best known and most used
measure of discrepancy
between observed and expected values are the Pearson residuals
\begin{equation} \label{eq:Pearson}
r_{ij} \quad = \quad \frac{n_{ij} - \hat n_{ij}}{\sqrt{\hat n_{ij}}}.
\end{equation}
Therefore, a rather intuitive idea is to reject the null hypothesis when
there are residuals which are too extreme, i.e., not close enough to
zero. The most convenient way to aggregate the $I \times J$ residuals
to one test statistic is their squared sum
\begin{equation} \label{eq:ChiSquare}
X^2 \quad = \quad \sum_{i, j}r_{ij}^2,
\end{equation}
because this is known to have a limiting $\chi^2$ distribution with $(I-1)(J-1)$
degrees of freedom under the null hypothesis.
This is the well-known $\chi^2$ test for independence in 2-way tables. 
Now, when the $chi^2$ test statistic turns out to be significant for some data, 
it seems natural to go back to its components, i.e. the  residuals, for a more detailed analysis.

Association plots \citep{vcd:Cohen:1980} visualize the table of Pearson residuals:
each cell is represented by a rectangle that has (signed) height
proportional to the corresponding Pearson residual $r_{ij}$ and width proportional to the
square root of the expected counts $\sqrt{\hat n_{ij}}$. Thus, the area is proportional to
the raw residuals $n_{ij} - \hat n_{ij}$. The sign of the residual is redundantly
coded by the rectangle's color and its position relative to the baseline.

Figure \ref{fig:assoc-classic1} shows the association plot
(produced by the implementation in {\sf R} `base') for the
variables `Hair' and `Eye' of the well-known `HairEyeColor' data
set (Hair and Eye colors of 264 male and 328 female statistics students). 
The biggest tiles are easy to depict: e.g., the tiles for 
brown and blue eyes, given blond hair, seem to represent important residuals. 
But for the others, their classification in important and less important 
categories seems not obvious. However, with some more information
visualized, this task could be facilitated.

\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htbp]
\begin{center}
<<assoc-classic1,fig=TRUE,echo=FALSE,height=6,width=7,results=hide>>=
base::assocplot(t(HairEyeColor[,,2]))
@
\caption{Association plot for `Hair' and `Eye' colors of female students.}
\label{fig:assoc-classic1}
\end{center}
\end{figure}

\section{Improved visualization through residual shading}

We propose to use a color-shading similar to Michael Friendly's
enhancements of the mosaic plot \cite[a graphical tool for the 
visualization of the observed frequencies in a contingency table; 
see][]{vcd:Hartigan+Kleiner:1984}:
this extension \citep{vcd:Friendly:1994} 
uses a color coding of the tiles to visualize deviations
(residuals) from a given log-linear model fitted to the table, that is, from
the expected frequencies under some independence hypothesis. 
Positive and negative signs of the residuals are coded by rectangles with
solid and dashed borders respectively. Furthermore, residuals can be
classified according to specified shading levels: per default,
residuals exceeding an absolute
value of 2 are shaded light blue and red respectively, those that even
exceed an absolute value of 4 are shaded with full saturation. The heuristic
behind this shading is that
the Pearson residuals are approximately standard normal which implies
that the highlighted cells are those with
residuals \emph{individually} significant at approximately the 5\% and 0.01\%
level. But the main purpose of the shading is not to visualize
significance but the \emph{pattern} of
deviation from independence \citep[p.~109]{vcd:Friendly:2000}.

Applying this color scheme to association plots similarly facilitates
the detection of (in)dependence patterns. Consider the `HairEyeColor' example
introduced in the previous section: Figure \ref{fig:assoc-improved1}
shows the same residuals than Figure \label{fig:assoc-classic1}, but
now, the color shading help us to sort the residuals into the 
three categories: important--less important--unimportant and thus
emphasizes the associational pattern in the underlying data.

\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htbp]
\begin{center}
<<assoc-improved1,fig=TRUE,echo=FALSE,height=6,width=7,results=hide>>=
grid.assocplot(HairEyeColor[,,2], gp = gp.shading)
@
\caption{Extended association plot for `Hair' and `Eye' colors of female students.}
\label{fig:assoc-improved1}
\end{center}
\end{figure}

Another example is given in Figure \ref{fig:assoc-classic2}:
this time, we cross-tabulate the variables `Eye' and `Sex'.
The big tiles for brown Eyes suggest a strong asymmetry between
male and female students, and hence rejection of the independence
hypothesis. However, the $\chi^2$ test statistic is not significant at
a 5\% level: in this example, its value is 7.28, and the corresponding
$P$ value approximately $0.063$. Apparently, the relative size of the
tiles is insufficient to assess the ``strength'' of association
between two variables; again, information on the absolute size of the
residuals would be useful.
Using the extended shading (Figure \ref{fig:assoc-improved2}), we see at first glance
that \emph{no} residual is bigger than 2 (respectively smaller than -2 for
negative ones) because simply no tile is shaded. In fact, as we can depict from
the legend, the overall range of the residuals is approximately $[-1.5;1.5]$.

\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htbp]
\begin{center}
<<assoc-classic2,fig=TRUE,echo=FALSE,height=6,width=7,results=hide>>=
base::assocplot(margin.table(HairEyeColor, 2:3))
@
\caption{Association plot for `Hair' and `Sex' in the `HairEyeColor' data.}
\label{fig:assoc-classic2}
\end{center}
\end{figure}

\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htbp]
\begin{center}
<<assoc-improved,fig=TRUE,echo=FALSE,height=6,width=7,results=hide>>=
grid.assocplot(t(margin.table(HairEyeColor, 2:3)), gp = gp.shading)
@
\caption{Extended association plot for `Hair' and `Sex' in the `HairEyeColor' data.}
\label{fig:assoc-improved2}
\end{center}
\end{figure}

\section{Extension to multi-way tables}

Independence problems do not only occur in 2-way tables, but 
are also important in tables of higher dimensionality where they
can follow much more complex patterns.
These are again defined based on the underlying table of theoretical cell probabilities
$(\pi_{ij\dots})$ with more than two dimensions. Apart from the
analysis of all pairwise associations, models of interest include,
e.g., the null hypotheses of conditional independence:

\[\pi_{ijk\dots} = \pi_{i|k\dots}\pi_{j|k\dots}\]

A quick overview of the mutual independence structure of a multi-way table
can be given by a matrix of plots where each cell contains an
association plot of the corresponding row and column variables. Such an
\emph{association pairsplot} allows us to
quickly scan the association plots for all variable combinations. As
an example, we again use the HairEyeColor data (see Figure
\ref{fig:HEC-pairs}): only the cells corresponding to the variables
`Hair' and `Eye' contain an ``interesting'' association plot with
colored residuals.

\begin{figure}[htbp]
\begin{center}
<<UCB-mosaic-signif,fig=TRUE,echo=FALSE,height=8,width=8>>=
 panel.assocplot <- function (x, i, j, ..., axes, abbreviate) grid.assocplot(margin.table(x, c(i,j)), ..., panel = T, axis.labels = F, labels = F, main = NULL) 
grid.mosaicpairs(aperm(HairEyeColor), panel.upper= panel.assocplot, panel.lower = panel.assocplot, gp = gp.shading, main = NULL)
@
\caption{Extended association pairs for the `HairEyeColor' data.}
\label{fig:HEC-pairs}
\end{center}
\end{figure}

To visualize conditional independence, we could use conditioning
plots: like in trellis displays, we produce a separate plot
for each level of a conditioning variable (in the case of two
or more conditioning variables, for each level combination). 
This can be illustrated using the famous admissions data of the University of
California at Berkley (UCB) which is available in base \textsf{R}.
In this data, the question whether there is sex
discrimination at the UCB leads to the result that although women seem to
be disadvantaged at the aggregated level there is no sex discrimination
in the department strata---with the very exception of one department
in which women are {\em more} likely to be admitted than would be plausible
under independence. Exactly this is illustrated in the conditioning
association plot in Figure \ref{fig:UCB-assoc-signif}.

\begin{figure}[htbp]
\begin{center}
<<UCB-assoc-signif,fig=TRUE,echo=FALSE,height=10,width=10>>=
tabplot(UCBAdmissions, gp = gp.shading)
@
\caption{Extended conditioning association plots for the `UCB Admissions' data.}
\label{fig:UCB-assoc-signif}
\end{center}
\end{figure}

\section{Implementation enhancements}

The current implementation of association plots in \textsf{R} suffers
from two main disadvantages: First, it is not easy to recycle the
plots in conditioning plots or pairs plots as
they have been implemented using \textsf{R}'s base graphics engine where in
general plotting to relative coordinates is not supported.
The new implementation was written from scratch in \texttt{grid} offering
much more versatility amongst some minor advantages and convenient
improvements. Second, the graphics parameters of the rectangles in the
association plots (like in almost all standard \textsf{R}
plots), such as color and line type, cannot be specified for each cell
by the user. To overcome this, the current implementation in \texttt{vcd}
allows the user to specify either arrays of graphics parameters
of the same dimensionality as the object being plotted or a function
which computes these graphics parameters based on the original table
and its Pearson residuals. Functions are provided for shading schemes
like the one described in the previous section.

\section{Conclusion}
We suggest a set of enhancements for visualizing the independence
problem in 2-way tables using association plots. The
extensions aim at improving the visualization by displaying
the size of the residuals, and by extending the concept of association
plots to multi-way tables. Furthermore, a new
implementation is outlined based on the graphics package \texttt{grid}
which provides more modular design and more flexible specification
of graphical parameters.

Our work is still not at its end, though: for example, the plots for
multi-way tables currently do not use the same scale for all subplots,
and thus residuals of different subplots are not
comparable. Furthermore, the current color scheme only allows the
detection of ``patterns'' of independence. It would be nice, however, 
that the shading levels were
chosen such that a true visual test of independence can be performed,
that is, such that the presence of ``significant'' residuals lead to a
rejection of the hypothesis of independence. Current work includes the
development of such color schemes, based on an alternative test
statistic---the maximum of the absolute values of the pearson residuals.

\bibliographystyle{asa}
\bibliography{vcd}

\end{document}
% LocalWords:  proofness

