\documentclass[10pt,a4paper,twoside]{article}
\usepackage{fancyheadings}

%% Packages:
\usepackage{graphicx,color,a4wide,thumbpdf,rotating,hyperref}
%% need no \usepackage{Sweave}

%% BibTeX
\usepackage[authoryear,round,longnamesfirst]{natbib}
\bibliographystyle{asa}
\bibpunct{(}{)}{;}{a}{}{,}

%% new commands
\let\code=\texttt
\let\proglang=\textsf
\newcommand{\pkg}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\given}{\, | \,}

%% Colors
\definecolor{Red}{rgb}{0.7,0,0}
\definecolor{Blue}{rgb}{0,0,0.8}
\definecolor{hellgrau}{rgb}{0.55,0.55,0.55}

%% mimic JCGS style
\renewcommand{\section}{\secdef \mysec \mysecnn}
\newcommand{\mysec}[2][default]{\vspace{1.3\baselineskip}%
  \pdfbookmark[1]{#1}{Section.\thesection.#1}%
  \refstepcounter{section}%
  {\begin{center} \large \bf \thesection. \uppercase{#1} \end{center}}%
  \vspace{0.7\baselineskip}}
\newcommand{\mysecnn}[1]{\vspace{1.3\baselineskip}%
  {\begin{center}\large \bf \uppercase{#1} \end{center}}%
  \vspace{0.7\baselineskip}}

\renewcommand{\subsection}{\secdef \mysubsec \mysubsecnn}
\newcommand{\mysubsec}[2][default]{\vspace{1.2\baselineskip}%
  \pdfbookmark[2]{#1}{Subsection.\thesubsection.#1}%
  \refstepcounter{subsection}%
  \noindent%
  {\large \textbf{\thesubsection{} {\sc#1}}} \vspace{.7\baselineskip}}
\newcommand{\mysubsecnn}[1]{\vspace{1.2\baselineskip}%
  \noindent%
  {\large \textbf{{\sc #1}}} \vspace{.7\baselineskip}}
\renewcommand{\abstractname}{}
\renewcommand{\refname}{REFERENCES}

%% Hyperref
\hypersetup{%
  pdftitle = {Residual-based Shadings for Visualizing (Conditional) Independence},
  pdfsubject = {Residual-based Shadings},
  pdfkeywords = {association plots, conditional inference, contingency tables, HCL colors, HSV colors, mosaic plots},
  pdfauthor = {Achim Zeileis, David Meyer, Kurt Hornik},
  %% change colorlinks to false for pretty printing
  colorlinks = {false},
  linkcolor = {Blue},
  citecolor = {Blue},
  urlcolor = {Red},
  hyperindex = {true},
  linktocpage = {true},
}


\begin{document}

\pagestyle{fancy}
\thispagestyle{fancyplain}
\headrulewidth0pt
\lhead[]{}
\chead[]{}
\rhead[]{}
\lfoot[This is a preprint of an article accepted for publication in \textit{Journal of Computational and Graphical Statistics}.
Copyright {\copyright} 2007 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America]%
{This is a preprint of an article accepted for publication in \textit{Journal of Computational and Graphical Statistics}.
Copyright {\copyright} 2007 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America}
\cfoot[]{}
\rfoot[]{}

\begin{center}
\textbf{\LARGE Residual-based Shadings for Visualizing\\[.15cm] (Conditional) Independence}

\vspace{0.5cm}
{\large Achim \textsc{Zeileis}, David \textsc{Meyer}, and Kurt \textsc{Hornik}}

%% \vspace{0.3cm}
%% \textit{\large Wirtschaftsuniversit\"at Wien, Augasse 2--6, 1090 Wien, Austria}\\[0.14cm]
%% {\large \textit{E-mail:} \texttt{Firstname.Lastname@wu-wien.ac.at}}
\end{center}

\SweaveOpts{engine=R,eps=FALSE,echo=FALSE,results=hide}
\setkeys{Gin}{width=0.8\textwidth}

<<load_data>>=
library("vcd")

data("Arthritis", package = "vcd")
art <- xtabs(~ Treatment + Improved, data = Arthritis, subset = Sex == "Female")
names(dimnames(art))[2] <- "Improvement"

data("pistonrings", package = "HSAUR")
pring <- pistonrings
names(dimnames(pring)) <- c("Compressor", "Leg")
dimnames(pring)[[2]][2] <- "center"
 
data("alzheimer", package = "coin")
alz <- xtabs(~ smoking + disease + gender, data = alzheimer)
dimnames(alz)[[2]] <- c("Alzheimer's", "Dementia", "Other")
names(dimnames(alz)) <- c("Smoking", "Disease", "Gender")

data("Punishment", package = "vcd")
pun <- xtabs(Freq ~ memory + attitude + age + education, data = Punishment)
dimnames(pun) <- list(Memory = c("yes", "no"), Attitude = c("no", "moderate"),
  Age = c("15-24", "25-39", "40+"), Education = c("Elementary", "Secondary", "High"))

myseed <- 1071
nrep <- 5000
nrep_char <- "5,000"
recompute <- TRUE
@

<<inference>>=
if(recompute) {
  set.seed(myseed)
  art_max <- coindep_test(art, n = nrep)
  set.seed(myseed)
  art_chisq <- coindep_test(art, n = nrep, indepfun = function(x) sum(x^2))

  set.seed(myseed)
  pring_max <- coindep_test(pistonrings, n = nrep)
  set.seed(myseed)
  pring_chisq <- coindep_test(pistonrings, n = nrep, indepfun = function(x) sum(x^2))

  set.seed(myseed)
  alz_dmax <- coindep_test(alz, "Gender", n = nrep)
  set.seed(myseed)
  alz_maxchisq <- coindep_test(alz, "Gender", n = nrep, indepfun = function(x) sum(x^2))
  set.seed(myseed)
  alz_sumchisq <- coindep_test(alz, "Gender", n = nrep, indepfun = function(x) sum(x^2), aggfun = sum)
  set.seed(myseed)
  alz_cotab <- cotab_coindep(alz, condvars = "Gender", n = nrep, margins = c(2, 1, 1, 2),
    varnames = FALSE)

  set.seed(myseed)
  pun_dmax <- coindep_test(pun, 3:4, n = nrep)
  set.seed(myseed)
  pun_maxchisq <- coindep_test(pun, 3:4, n = nrep, indepfun = function(x) sum(x^2))
  set.seed(myseed)
  pun_sumchisq <- coindep_test(pun, 3:4, n = nrep, indepfun = function(x) sum(x^2), aggfun = sum)
  set.seed(myseed)
  pun_cotab <- cotab_coindep(pun, condvars = 3:4, type = "assoc", n = nrep,
    varnames = FALSE, margins = c(2, 1, 1, 2), test = "maxchisq", interpolate = 1:2)
  set.seed(myseed)
  pun_cotab2 <- cotab_coindep(pun, condvars = 3:4, type = "mosaic", n = nrep,
    varnames = FALSE, margins = c(2, 1, 1, 2), test = "maxchisq", interpolate = 1:2)

  save(art_max, art_chisq,
       pring_max, pring_chisq,
       alz_dmax, alz_maxchisq, alz_sumchisq, alz_cotab,
       pun_dmax, pun_maxchisq, pun_sumchisq, pun_cotab, pun_cotab2,
       file = "JCGS-inference.rda")
} else {
  load("JCGS-inference.rda")
}
@

<<auxiliary_functions>>=
stat <- function(x, digits = 3) as.vector(round(x$statistic, digits = digits))
pval <- function(x, digits = 6) {
  oop <- options()
  on.exit(oop)
  options(scipen = 1000)
  as.vector(round(x$p.value, digits = digits))
}

hue.slice <- function(hue, grid.n = 101, type = c("HCL", "HSV"), plot = TRUE, fixup = FALSE)
{
  type <- match.arg(type)
  if(type == "HCL") {
    chroma = seq(0, 100, length = grid.n)
    luminance = seq(0, 100, length = grid.n)
    nc <- length(chroma)
    nl <- length(luminance)
    color.slice <- outer(chroma, luminance, function(y, x) hcl2hex(hue, x, y, fixup = fixup))
    xlab <- "chroma"
    ylab <- "luminance"
    main <- paste("hue =", round(hue, digits = 0))
  } else {
    chroma = seq(0, 1, length = grid.n)
    luminance = seq(0, 1, length = grid.n)
    nc <- length(chroma)
    nl <- length(luminance)
    color.slice <- outer(chroma, luminance, function(y, x) hsv(hue, x, y))
    xlab <- "saturation"
    ylab <- "value"
    main <- paste("hue =", round(hue, digits = 3))
  }
  if(plot) {
    plot(0.5, 0.5, xlim = range(chroma), ylim = range(luminance), type = "n", axes = FALSE,
         xlab = xlab, ylab = ylab, yaxs = "i", xaxs = "i", main = main)
    for(i in 1:(nc-1)) {
      rect(chroma[i], luminance[-nl], chroma[i] + 100/(nc-1), luminance[-1], border = color.slice[,i+1], col = color.slice[,i+1])
    }
    axis(1)
    axis(2)
    box()
  }
  colnames(color.slice) <- chroma
  rownames(color.slice) <- luminance
  attr(color.slice, "type") <- type
  class(color.slice) <- "slice"
  invisible(color.slice)
}
@


\begin{abstract}
Residual-based shadings for enhancing mosaic and association plots
to visualize independence models for contingency tables are extended
in two directions: (a)~perceptually uniform Hue-Chroma-Luminance (HCL)
colors are used and (b)~the
result of an associated significance test is coded by the appearance of
color in the visualization. For obtaining (a), a general strategy for
deriving diverging palettes in the perceptually-based HCL space is suggested. As for (b),
cut offs that control the appearance of color are computed in a data-driven
way based on the conditional permutation distribution of maximum-type
test statistics. The shadings are first established for the case of independence
in 2-way tables and then extended to more general independence models
for multi-way tables, including in particular conditional independence
models.\\[0.3cm]

\noindent \textbf{Key Words:} Association plots; Conditional inference; 
Contingency tables; HCL colors; HSV colors; Mosaic plots.
\end{abstract}

\section{Introduction} \label{sec:introduction}

Relationships between categorical variables are typically
analyzed based on the underlying contingency tables that can be explored
for (in)dependence. Two standard methods from the statistical tool box
are log-linear models \citep[see, e.g.,][]{vcd:Agresti:2002} for modeling
(in)dependence structures and mosaic plots \citep{vcd:Hartigan+Kleiner:1981} for 
bringing them out graphically. Both methods can also be combined such that
a certain mosaic plot visualizes a particular log-linear model by 
controlling splitting order and direction and shading of the tiles
in the mosaic display
\citep{vcd:Friendly:1994,vcd:Friendly:1999,vcd:Theus+Lauer:1999,vcd:Hofmann:2001}.
In particular, \cite{vcd:Friendly:1994} suggested a shading strategy
based on the residuals (typically, Pearson or deviance residuals) of the associated
log-linear model that elevates the mosaic plot from a display for frequencies
in a contingency table to a visualization technique that encompasses both observed
frequencies and residuals. This shading allows for judging the quality of a model
fit and spotting dependence patterns that have not been accounted for by the model.
Other techniques for visualizing dependence in contingency tables such as
association plots \citep{vcd:Cohen:1980} can also be enhanced by using this
residual-based shading.

In this paper, the shading of \cite{vcd:Friendly:1994} is extended in two directions:
usage of perceptually-based HCL (Hue-Chroma-Luminance) colors and combination of
visualization and significance testing. Friendly's shading is typically implemented
in statistical software using color spaces such as HLS (Hue-Luminance-Saturation) or
HSV (Hue-Saturation-Value) colors. The dimensions of both spaces are only
poorly mapped to the perceptual dimensions of the
human visual system \citep{vcd:Brewer:1999,vcd:Ihaka:2003} which makes it more difficult
to properly read and interpret the corresponding plots. For overcoming this problem,
a general strategy for constructing diverging palettes in the perceptually-based HCL
space \citep{vcd:Ihaka:2003} is derived. To couple the visualization and the independence
model of a contingency table more tightly than in previous approaches, the residual-based
shading is extended such that appearance of color in the display is equivalent to significance
of the associated independence test. This is achieved by using data-driven cut offs
for the appearance of color computed from the conditional permutation distribution
\citep{vcd:Ernst:2004,vcd:Pesarin:2001} of maximum-type test statistics. The resulting
residual-based shadings are illustrated both for mosaic and association plots 
using real world data sets.

The remainder of the paper is structured as follows: Section~\ref{sec:2way} gives a
brief introduction to significance tests and visualization techniques for the
independence problem in 2-way contingency tables. Based on this, Section~\ref{sec:shadings}
introduces the extended residual-based shadings using perceptually uniform HCL colors
and combining visualization and significance testing. The results are generalized to
multi-way tables in Section~\ref{sec:3way} with a more detailed discussion of adapting
them to conditional independence problems. Section~\ref{sec:conclusions} summarizes the paper
and gives some concluding remarks.


\headrulewidth0pt
\lhead[\thepage]{}
\chead[\textit{Residual-based Shadings for Visualizing (Conditional) Independence}]{\textit{Achim Zeileis, David Meyer, Kurt Hornik}}
\rhead[]{\thepage}
\lfoot[{\small Copyright {\copyright} 2007 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America}]{{\small Copyright {\copyright} 2007 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America}}
\cfoot[]{}
\rfoot[]{}

\section{Independence in 2-way Tables}
\label{sec:2way}

In this section, the basic tools for testing and visualizing 
independence in 2-way tables are briefly reviewed. 
For illustration, a data set about treatment and improvement of
patients with rheumatoid arthritis from \cite{vcd:Koch+Edwards:1988}
is used. The data set is also discussed in \cite{vcd:Friendly:2000}
and the subset of the $59$ female patients from the study is given in
Table~\ref{tab:art}.

\begin{table}[b!]
\begin{center}
\caption{\label{tab:art} Treatment and improvement among $59$ patients
with rheumatoid arthritis.}

\begin{tabular}{rr|rrr}
\\
                   &         & \multicolumn{3}{|l}{\textbf{Improvement}} \\
                   &         & None & Some & Marked \\ \hline
\textbf{Treatment} & Placebo &   19 &    7 &      6 \\
                   & Treated &    6 &    5 &     16
\end{tabular}

\end{center}
\end{table}


\subsection{Tests}
\label{sec:tests}

To fix notations, we consider a 2-way contingency table with cell
frequencies $[n_{ij}]$ for $i = 1, \dots, I$ and $j = 1, \dots, J$
and row and column sums $n_{i+} = \sum_i n_{ij}$ and $n_{+j} = \sum_j n_{ij}$,
respectively.
Given an underlying distribution with theoretical cell probabilities
$\pi_{ij}$, the null hypothesis of independence of the two categorical
variables can be formulated as
\begin{equation} \label{eq:H0}
H_0: \; \pi_{ij} \quad = \quad \pi_{i+} \pi_{+j}.
\end{equation}

The estimated expected cell frequencies under $H_0$ are
$\hat n_{ij} = n_{i+}n_{+j}/n_{++}$. As well-established in the stastical literature,
a very closely related hypothesis is that of homogeneity which in particular leads to the same
expected cell frequencies and is hence not discussed explicitely below.
The probably best known and most used
measure of discrepancy between observed and expected values are the Pearson residuals
\begin{equation} \label{eq:Pearson}
r_{ij} \quad = \quad \frac{n_{ij} - \hat n_{ij}}{\sqrt{\hat n_{ij}}}.
\end{equation}
The most convenient way to aggregate the $I \times J$ residuals
to one test statistic is their sum of squares
\begin{equation} \label{eq:ChiSquare}
X^2 \quad = \quad \sum_{i, j}r_{ij}^2,
\end{equation}
because this is known to have an unconditional limiting $\chi^2$ distribution with $(I-1)(J-1)$
degrees of freedom under the null hypothesis.
This is the well-known $\chi^2$ test which is typically introduced first in statistics
textbooks when addressing the independence problem in 2-way tables
\citep[see, e.g.,][]{vcd:Agresti:2002}.

However, the sum of squares is not the only plausible way of capturing deviations
from zero in the residuals. There are many other conceivable functionals $\lambda(\cdot)$ which
lead to reasonable test statistics $\lambda([r_{ij}])$---and without further 
specification of a certain pattern of dependence no functional $\lambda(\cdot)$
uniformly dominates all others in terms of power of the resulting test procedure.
Therefore, the choice of the functional is usually also guided by the data analysis problem at
hand: one functional which is particularly suitable for identifying the cells responsible for
the `dependence' (i.e., significant departure from independence), if any, is the maximum of
the absolute values
\begin{equation} \label{eq:MaxAbs}
M \quad = \quad \max_{i, j} |r_{ij}|.
\end{equation}
Given a critical value $c_\alpha$ for this test statistic, all residuals whose
absolute values exceed $c_\alpha$ violate the null hypothesis of indendence at significance level
$\alpha$ \cite[][ch.~7]{vcd:Mazanec+Strasser:2000}. Thus, the interesting cells responsible
for the dependence can easily be identified.

Furthermore, an important reason for using the unconditional limiting distribution
for the $X^2$ statistic from Equation~\ref{eq:ChiSquare} was the closed form result
for the distribution. Recently, with the improving perfomance of computers,
conditional inference (or permutation tests, conditioning on the observations)---carried
out either by simulation or by computation of the (asymptotic) permutation distribution---have been receiving
increasing attention \citep[e.g.,][]{vcd:Ernst:2004,vcd:Pesarin:2001,vcd:Strasser+Weber:1999}. 
For testing the independence hypothesis from Equation~\ref{eq:H0}, using a permutation test is particularly
intuitive due to the permutation invariance (given row and column sums) of this problem.
Consequently, all results in this paper are based on conditional inference performed
by simulating the permutation distribution of test statistics of type
$\lambda([r_{ij}])$.

Note, that virtually all ideas discussed in this paper also extend straightforwardly to the situation
where other measures of discrepancy (such as, e.g., deviance residuals) are used
instead of the Pearson residuals $[r_{ij}]$.

For the arthritis data from Table~\ref{tab:art}, both tests indicate a clearly significant
dependence of improvement on treatment: the sum-of-squares statistic from Equation~\ref{eq:ChiSquare}
is $X^2 = \Sexpr{stat(art_chisq)}$ with a $p$ value of $p = \Sexpr{pval(art_chisq)}$,
and the maximum statistic from Equation~\ref{eq:MaxAbs} is $M = \Sexpr{stat(art_max)}$
with $p = \Sexpr{pval(art_max)}$. Both $p$ values have been computed
from a sample of size $\Sexpr{nrep_char}$ from the permutation distribution under independence
generated via sampling tables with the same row and column sums $n_{i+}$ and $n_{+j}$
using the \cite{vcd:Patefield:1981} algorithm and computing the respective statistic for 
each of these tables.


\subsection{Visualizations} \label{sec:visualization}

Two well-established visualization techniques for independence in 2-way tables are
mosaic plots and association plots. Both are suitable to bring out
departures of an observed table $[n_{ij}]$ from the estimated expected table $[\hat n_{ij}]$
in a graphical way. The latter focuses on the visualization of the Pearson residuals
$r_{ij}$ (under independence) while the former primarily displays the observed frequencies
$n_{ij}$.

\emph{Mosaic plots}
\citep{vcd:Hartigan+Kleiner:1981} can be seen as an extension of grouped
bar charts where width and height of the bars show the relative
frequencies of the two variables: a mosaic plot simply
consists of a collection of tiles with areas
proportional to the observed cell frequencies as shown
in the left panel of Figure~\ref{fig:classic}. A rectangle corresponding
to $100$ percent of the observations is first split horizontally with respect to 
the treatment frequencies and then vertically with respect to the conditional
improvement frequencies. This shows that there have been more placebo than treated 
patients with no improvement and vice versa for marked improvement.
This strategy of splitting with respect to conditional frequencies given all
previous variables can also directly be used for visualizing multi-way tables
\citep[see][for an overview of how to construct and read mosaic displays]{vcd:Hofmann:2003}.

\emph{Association plots}
\citep{vcd:Cohen:1980} visualize the table of Pearson residuals:
each cell is represented by a rectangle that has (signed) height
proportional to the corresponding Pearson residual $r_{ij}$ and width proportional to the
square root of the estimated expected counts $\sqrt{\hat n_{ij}}$. Thus, the area is proportional to
the raw residuals $n_{ij} - \hat n_{ij}$. The association plot for the arthritis
data is shown in the right panel of Figure~\ref{fig:classic} which leads to the
same interpretation as the mosaic plot: there are more placebo patients with no 
improvement and fewer with marked improvement than expected under independence---vice
versa for the treated patients.

\clearpage

\setkeys{Gin}{width=\textwidth}
\begin{figure}[t!]
\begin{center}
<<classic_plots,fig=TRUE,height=6,width=11>>=
grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2)))
pushViewport(viewport(layout.pos.col=1, layout.pos.row=1))
mosaic(art, newpage = FALSE, margins = c(2.5, 4, 2.5, 3))
popViewport()
pushViewport(viewport(layout.pos.col=2, layout.pos.row=1))
assoc(art, newpage = FALSE, margins = c(5, 2, 5, 4))
popViewport(2)
@
\caption{Classic mosaic and association plot for the arthritis data.}
\label{fig:classic}
\end{center}
\end{figure}

\section{Residual-based Shadings} \label{sec:shadings}

Colors are commonly used to enhance mosaic and association plots. To integrate
a visualization of the residuals $[r_{ij}]$ into the mosaic display---which
in its `raw' version only visualizes the observed frequencies $[n_{ij}]$---\cite{vcd:Friendly:1994}
suggested a residual-based shading for the mosaic tiles that can also be applied
to the rectangles in association plots \citep{vcd:Meyer+Zeileis+Hornik:2003}. 
In this section, we first briefly review the \cite{vcd:Friendly:1994} shading, 
before we suggest different colors and a combination of visualization and significance
testing to extend these residual-based shadings.

\subsection{Friendly Shading} \label{sec:Friendly}

The extensions of \cite{vcd:Friendly:1994} to mosaic plots provide a
substantial improvement of the original mosaic plots enhancing them
from a plot for contingency tables to a visualization technique for
log-linear models and their residuals---and thus also for independence problems including
2-way tables as the simplest case.

The idea is to use a color coding for the mosaic tiles that visualizes the
sign and absolute size of each residual $r_{ij}$: Cells corresponding to small
residuals ($|r_{ij}| < 2$) are shaded white. Cells with medium sized residuals
($2 \le |r_{ij}| < 4$) are shaded light blue and light red for positive and negative
residuals, respectively. Cells with large residuals ($|r_{ij}| \ge 4$) are shaded
with a fully saturated blue and red, respectively. Mosaic plots enhanced by this 
shading can thus also bring out departures from independence (or other log-linear 
models in multi-way tables) graphically and visualize patterns of dependence.
The heuristic for choosing the cut offs $2$ and $4$ is that the Pearson residuals
are approximately standard normal which implies that the highlighted cells are those with
residuals \emph{individually} significant at approximately the $\alpha = 0.05$ and $\alpha = 0.0001$
levels. However, the main purpose of the shading is not to visualize significance but the \emph{pattern} of
deviation from independence \citep[p.~109]{vcd:Friendly:2000}. 

In addition to the shading of the rectangles themselves, the Friendly shading also
encompasses a choice of line type and line color of the borders of the rectangles
with similar ideas as described above. As both mosaic and association plots are
area-proportional visualization techniques, we focus on area shadings and always 
use solid black borders throughout this paper, but the extensions suggested in the
following could also be applied to control line type and color.

\subsection{Colors} \label{sec:colors}

The way the (light) blue and red colors are chosen differs somewhat between
various implementations of Friendly mosaic plots: In his original 
\proglang{SAS} implementation \citep[see][]{vcd:Friendly:2000}, Michael Friendly
uses colors from a palette based on HLS color space.
The implementation in the standard packages of the
\proglang{R} system for statistical computing and graphics
\citep{vcd:R:2006} employs colors from HSV space. 
Both spaces are rather similar transformations of RGB (Red-Green-Blue) space
\citep{vcd:Brewer:1999,vcd:Poynton:2000} and are very common implementations of
colors in many computer packages \citep{vcd:Moretti+Lyons:2002} making the generation
of the Friendly shading very simple. As both spaces can easily generate the
same colors, we only discuss HSV space in the following.

The HSV space looks like a cone \citep[see e.g.,][which also provides
links to comparisons with other color spaces discussed in this paper]{vcd:Wiki+HSV:2006}
with black at its peak (zero value) and full color wheels for different saturations at the other end,
around a white center (full value). Type and amount of color are controlled by hue
and saturation, respectively. Typically, polar coordinates $(h, s, v)$ rescaled for $s$ and $v$
to the interval $[0, 100]$ (or the unit interval) are used in this space, giving it the
appearance of a cylinder.
For generating colors in the Friendly shading, the following strategy is used:
The hue $h$ codes the sign of the residuals---$h = 0$ (red hue) is used for negative residuals,
$h = 240$ (blue hue) for positive residuals. The absolute size of the residuals
is then coded by the saturation $s$ which is set to $0$, $50$ and $100$, respectively,
for small/medium/large residuals. The value is always fixed at $v = 100$.
This is also depicted in the upper panel of Figure~\ref{fig:shadingHSVHCL} which shows
the saturation/value plane for the given hues $h = 0$ and $h = 240$. 
The full-color palette shows the
colors used for the Friendly shading when the residuals are increasing from left to right.
The reduced-color palette will be explained in Section~\ref{sec:significance}.

\setkeys{Gin}{width=.8\textwidth}
\begin{figure}[p]
\begin{center}
<<shading_HSV>>=
png(file = "shading_HSV.png", height = 525, width = 600)
## generate colors
hue23 <- hue.slice(2/3, grid.n = 101, plot = FALSE, type = "HSV")
hue0 <- hue.slice(0, grid.n = 101, plot = FALSE, type = "HSV")
saturation <- as.numeric(colnames(hue23))
value <- as.numeric(rownames(hue23))

## select those with value >= 0.5
hue23 <- hue23[value >= .5, ]
hue0 <- hue0[value >= .5, ]
value <- value[value >= .5]
nl <- nrow(hue23)
nc <- ncol(hue23)

## plot 2 slides from HSV space
plot(0.5, 0.5, xlim = c(-1, 1), ylim = c(0, 1), type = "n", axes = FALSE,
       xlab = "", ylab = "", yaxs = "i", xaxs = "i", main = "")
for(i in 1:(nc-1)) {
  rect(saturation[i], value[-nl], saturation[i] + 1/(nc-1), value[-1], border = hue23[,i+1], col = hue23[,i+1])
}
for(i in 1:(nc-1)) {
  rect(-saturation[i], value[-nl], -(saturation[i] + 1/(nc-1)), value[-1], border = hue0[,i+1], col = hue0[,i+1])
}
axis(2, at = c(50, 75, 100)/100, labels = c(50, 75, 100))
axis(4, at = c(50, 75, 100)/100, labels = c(50, 75, 100))
axis(3, at = -4:4*.25, labels=c(4:0*25, 1:4*25))
mtext(c("hue = 0", "hue = 240"), side = 3, at = c(-.5, .5), line = 3, cex = 1.2)
mtext("saturation", side = 3, at = 0, line = 2)
mtext("value", side = 2, at = .75, line = 2)
mtext("value", side = 4, at = .75, line = 2)
lines(c(-1, 1), c(.5, .5))

## full colors
rect(-1, 0.95, -.90, 1, col = hsv(0, 1, 1))
rect(-0.45, 0.95, -.55, 1, col = hsv(0, 0.5, 1))
rect(-.05, .95, .05, 1, col = hsv(2/3, 0, 1))
rect(0.45, 0.95, .55, 1, col = hsv(2/3, 0.5, 1))
rect(.90, .95, 1, 1, col = hsv(2/3, 1, 1))

text(-1, .33, "full color", pos = 4, cex = 1.2)
rect(-1, .20, -.80, .30, col = hsv(0, 1, 1))
rect(-.40, .20, -0.6, .30, col = hsv(0, 0.5, 1))
rect(-.20, .20, 0, .30, col = hsv(0, 0, 1))
rect(0, .20, .20, .30, col = hsv(2/3, 0, 1))
rect(0.4, .20, .60, .30, col = hsv(2/3, .5, 1))
rect(.80, .20, 1, .30, col = hsv(2/3, 1, 1))

lines(c(-.9, -.55), c(0.975, .975), lty = 2)
lines(c(-.45, -.05), c(0.975, .975), lty = 2)
lines(c(.45, .05), c(0.975, .975), lty = 2)
lines(c(.9, .55), c(0.975, .975), lty = 2)

## reduced colors
rect(-1, 0.5, -.90, 0.55, col = hsv(0, 1, 0.5))
rect(-0.45, 0.5, -.55, 0.55, col = hsv(0, 0.5, 0.5))
rect(-.05, .5, .05, 0.55, col = hsv(2/3, 0, 0.5))
rect(0.45, 0.5, .55, 0.55, col = hsv(2/3, 0.5, 0.5))
rect(.90, .5, 1, 0.55, col = hsv(2/3, 1, 0.5))

text(-1, .13, "reduced color", pos = 4, cex = 1.2)
rect(-1, 0, -.80, .10, col = hsv(0, 1, 0.5))
rect(-.60, 0, -.4, .10, col = hsv(0, 0.5, 0.5))
rect(-.20, 0, 0, .10, col = hsv(0, 0, 0.5))
rect(0, 0, .20, .10, col = hsv(2/3, 0, 0.5))
rect(0.4, 0, .60, .1, col = hsv(2/3, .5, 0.5))
rect(.80, 0, 1, .10, col = hsv(2/3, 1, 0.5))

lines(c(-.9, -.55), c(0.525, .525), lty = 2)
lines(c(-.45, -.05), c(0.525, .525), lty = 2)
lines(c(.45, .05), c(0.525, .525), lty = 2)
lines(c(.9, .55), c(0.525, .525), lty = 2)
dev.off()
@
\includegraphics{shading_HSV}

%% height=7,width=8 for PDF

<<shading_HCL>>=
png(file = "shading_HCL.png", height = 525, width = 600)
## generate colors
hue260 <- hue.slice(260, grid.n = 101, plot = FALSE)
hue360 <- hue.slice(360, grid.n = 101, plot = FALSE)
mychroma <- as.numeric(colnames(hue260))
luminance <- as.numeric(rownames(hue260))

## select those with lumincance >= 50
hue260 <- hue260[luminance >= 50, ]
hue360 <- hue360[luminance >= 50, ]
luminance <- luminance[luminance >= 50]
nc <- ncol(hue260)
nl <- nrow(hue260)

## plot 2 slides from HCL space
plot(0.5, 0.5, xlim = c(-100, 100), ylim = c(0, 100), type = "n", axes = FALSE,
       xlab = "", ylab = "", yaxs = "i", xaxs = "i", main = "")
for(i in 1:(nc-1)) {
  rect(mychroma[i], luminance[-nl], mychroma[i] + 100/(nc-1), luminance[-1], border = hue260[,i+1], col = hue260[,i+1])
}
for(i in 1:(nc-1)) {
  rect(-mychroma[i], luminance[-nl], -(mychroma[i] + 100/(nc-1)), luminance[-1], border = hue360[,i+1], col = hue360[,i+1])
}
axis(2, at = c(50, 70, 90, 100), labels = c(50, 70, 90, 100))
axis(4, at = c(50, 70, 90, 100), labels = c(50, 70, 90, 100))
axis(3, at = -4:4*25, labels=c(4:0*25, 1:4*25))
mtext(c("hue = 0", "hue = 260"), side = 3, at = c(-50, 50), line = 3, cex = 1.2)
mtext("chroma", side = 3, at = 0, line = 2)
mtext("luminance", side = 2, at = 75, line = 2)
mtext("luminance", side = 4, at = 75, line = 2)
lines(c(-100, 100), c(50, 50))

## full colors
rect(-100, 47.5, -90, 52.5, col = hcl2hex(0, 100, 50))
rect(-55, 67.5, -45, 72.5, col = hcl2hex(0, 50, 70))
rect(-5, 95, 5, 100, col = hcl2hex(260, 0, 100))       ## grey vs. white
rect(-5, 87.5, 5, 92.5, col = hcl2hex(260, 0, 90))     ## grey vs. white
rect(45, 67.5, 55, 72.5, col = hcl2hex(260, 50, 70))
rect(90, 47.5, 100, 52.5, col = hcl2hex(260, 100, 50))

text(-100, 33, "full color", pos = 4, cex = 1.2)
rect(-100, 20, -80, 30, col = hcl2hex(0, 100, 50))
rect(-60, 20, -40, 30, col = hcl2hex(0, 50, 70))
rect(-20, 20, 0, 30, col = hcl2hex(0, 0, 90))       
rect(0, 20, 20, 30, col = hcl2hex(260, 0, 90))
#white# rect(-20, 20, 0, 30, col = hcl2hex(0, 0, 100))
#white# rect(0, 20, 20, 30, col = hcl2hex(260, 0, 100))
rect(40, 20, 60, 30, col = hcl2hex(260, 50, 70))
rect(80, 20, 100, 30, col = hcl2hex(260, 100, 50))

lines(c(-45, -5), c(72.5, 87.5), lty = 2)
lines(c(45, 5), c(72.5, 87.5), lty = 2)
lines(c(-95, -55), c(52.5, 67.5), lty = 2)
lines(c(95, 55), c(52.5, 67.5), lty = 2)

## reduced colors
rect(-25, 47.5, -15, 52.5, col = hcl2hex(0, 20, 50))
rect(-15, 67.5, -5, 72.5, col = hcl2hex(0, 10, 70))
rect(5, 67.5, 15, 72.5, col = hcl2hex(260, 10, 70))
rect(25, 47.5, 15, 52.5, col = hcl2hex(260, 20, 50))


text(-100, 13, "reduced color", pos = 4, cex = 1.2)
rect(-60, 0, -40, 10, col = hcl2hex(0, 20, 50))
rect(-40, 0, -20, 10, col = hcl2hex(0, 10, 70))
rect(-20, 0, 0, 10, col = hcl2hex(0, 0, 90))
rect(0, 0, 20, 10, col = hcl2hex(260, 0, 90))
rect(20, 0, 40, 10, col = hcl2hex(260, 10, 70))
rect(40, 0, 60, 10, col = hcl2hex(260, 20, 50))

lines(c(-18.75, -11.25), c(52.5, 67.5), lty = 2)
lines(c(-8.75, -1.25), c(72.5, 87.5), lty = 2)
lines(c(18.75, 11.75), c(52.5, 67.5), lty = 2)
lines(c(8.75, 1.25), c(72.5, 87.5), lty = 2)
dev.off()
@
\includegraphics{shading_HCL}
\caption{Residual-based shadings in HSV (upper) and HCL space (lower).}
\label{fig:shadingHSVHCL}
\end{center}
\end{figure}

Although this HSV-based shading is already very useful for enhancing mosaic and
association plots and although HSV is a very commonly available implementation of
color spaces, HSV color space in general and the Friendly shading in particular have
a number of disadvantages. Most importantly, HSV colors are not perceptually
uniform because the three HSV dimensions map only poorly to the three
perceptual dimensions of the human visual system  \citep{vcd:Brewer:1999,vcd:Ihaka:2003}.
Consequently, the HSV dimensions are confounded, e.g., saturation
is not uniform across different hues. A fully saturated blue $(240, 100, 100)$ is
perceived to be much darker than a fully saturated red $(0, 100, 100)$ or green $(120, 100, 100)$.
This makes it more difficult for the human eye to judge the size of shaded areas
and can therefore lead to color-caused optical illusions when used in statistical graphs
\citep{vcd:Cleveland+McGill:1983}. Furthermore, flashy fully saturated HSV colors are
good for drawing attention to a plot, but hard to look at for a longer time \citep{vcd:Ihaka:2003}
which makes graphics shaded with such colors harder to interpret. Finally, white is employed as
the neutral color for small residuals in the Friendly shading, however typically
grey is found to convey neutrality or un-interestingness much better than white
\citep{vcd:Brewer:1999}.

Alternative ways to choose colors have been available for a long time, but have
been only slowly adopted for implementations of colors in computer packages in 
general and for shading in statistical graphs in particular. The idea of using
perceptually-based colors that are `in harmony' goes back until at least \cite{vcd:Munsell:1905} 
who introduced a color notation for balanced colors. Based on similar principles, Cynthia
Brewer and co-workers suggested different types of palettes (qualitative/sequential/diverging)
and provided the online tool \pkg{ColorBrewer.org} \citep{vcd:Harrower+Brewer:2003} for
selecting an appropriate palette for a specific problem. Furthermore, the
\citet[CIE,][]{vcd:CIE:2004} introduced the two perceptually-based 
color spaces CIELAB and CIELUV where the latter is typically preferred for 
emissive color technologies such as computer displays. \cite{vcd:Ihaka:2003} discusses
how CIELUV colors can be used for choosing qualitative palettes for statistical graphics such as barplots.
By taking polar coordinates in CIELUV space, it is called HCL (Hue-Chroma-Luminance) space
and qualitative palettes can easily be chosen by using a range of hues for
fixed values of chroma and luminance. Such colors are always balanced towards
the same grey and thus do not have the problem of varying saturations that the HSV colors have.
In general, the HCL space offers much better support for selecting balanced palettes
along simple paths through the space, which will be exploited below.

In the following, we discuss how ideas similar to those from \cite{vcd:Ihaka:2003}
can be used for deriving diverging HCL palettes that provide a suitable translation
of the ideas from the Friendly shading to perceptually uniform HCL colors. 
The HCL space looks like a distorted double cone with black (zero luminance) at one end and white
at the other (full luminance). In its middle, there is a full color wheel for different
values of chroma (that controls the colorfulness). Unfortunately, the HCL space is not as
regular as the HSV space: although its dimensions are usually also given by a
hue ranging in $[0, 360]$ degrees and chroma and luminance ranging in $[0, 100]$
percent, not all combinations $(h, c, l)$ yield valid HCL colors and the admissable combinations
of $c$ and $l$ vary across different hues $h$. For the task of constructing
a diverging palette, this problem can easily be overcome as we just need two different
hues (a `negative' and a `positive' hue) and hence we can choose two hues that correspond to 
similar shapes in the chroma/luminance plane. The lower panel of Figure~\ref{fig:shadingHSVHCL}
shows two such planes side by side for the hues $h = 0$ and $h = 260$.\footnote{The hue
$h = 260$ is chosen rather than $h = 240$ because its chroma/luminance plane is most similar,
as assessed by the area of the symmetric difference of the planes, to that of $h = 0$.}
To obtain a sequence of colors with the similar properties as the Friendly shading, the palette starts
at a fully saturated red $(0, 100, 50)$, goes via a neutral color, ends at a fully saturated
blue $(260, 100, 50)$, and uses linear interpolation in between. Instead of using white
$(0, 0, 100)$ as the neutral color, a light grey $(0, 0, 90)$ is employed as motivated above.
The diverging palette (see the full-color palette in Figure~\ref{fig:shadingHSVHCL})
uses both chroma---i.e., the colorfulness---and luminance---i.e., 
the amount of grey---to code the absolute size of the quantity visualized---i.e., the
residuals $r_{ij}$---when applied to the independence problem. By changing the neutral
color or by changing the maximum chroma, respectively, this can be changed to using only
chroma or luminance for this purpose, but using both is a very effective way
of visualization (i.e., yields palettes with more distinctive colors)
and corresponds more closely with the properties of the Friendly shading.

Applying these palettes to the mosaic plot of the arthritis data yields
the displays in the upper middle and right panels of Figure~\ref{fig:shadings} (with
data-driven cut offs as defined Section~\ref{sec:significance}). This illustrates
that especially the full color cells (in the `marked' column) are less flashy and more
balanced in the HCL shading as compared to the HSV shading.


\subsection{Significance} \label{sec:significance}

The shading scheme of \cite{vcd:Friendly:1994} was suggested to visualize
the pattern of dependence in contingency tables, as discussed above, but
the presence (or absence) of colors in a plot also always conveys an
impression of interestingness (or un-interstingness, respectively). That is,
viewers might be tempted to interpret the absence of color in a plot
as a clue that there is no significant departure from independence. Or vice
versa, colored cells would convey the impression that there is significant
dependence. Currently, both are not true as can be seen in the upper left panel
of Figure~\ref{fig:shadings} which shows the mosaic display for the arthritis
data with Friendly shading. Although there is significant dependence (as according
to both the maximum and sum-of-squares tests), no residual exceeds an absolute value of $2$
and hence no cell is colored.
Of course, it can be argued that the shading was not designed for this purpose
and that different cut offs than $2$ and $4$ should be used here. However,
in this situation, it would be nice if such cut offs could be chosen automatically in a
data-driven way. Strategies for this are derived in the following.

The Friendly shading can be interpreted to be a visualization of the maximum
statistic $M$ from Equation~\ref{eq:MaxAbs} which always employs the critical values $c_\alpha$
$2$ and $4$. However, it is not clear to which
significance levels $\alpha$ these critical values correspond because the distribution
of $M$ depends on the underlying contingency table. The natural solution to this
problem is to compute the critical values from the distribution of $M$ in a data-driven
way (i.e., for the table visualized) and use these instead of the hard-coded values
$2$ and $4$. In the upper middle and right panels of Figure~\ref{fig:shadings} this is done for
the arthritis data by employing the critical values
$\Sexpr{round(as.vector(art_max$qdist(0.9)), digits = 2)}$ at level $\alpha = 0.1$ and
$\Sexpr{round(as.vector(art_max$qdist(0.99)), digits = 2)}$ at level $\alpha = 0.01$
(using the diverging HSV and HCL palettes, respectively) derived from the permutation distribution of $M$ for 
the arthritis data as described in Section~\ref{sec:tests}. By using these cut offs, the presence of color
in the plot is equivalent to significance (of the maximum statistic $M$) at 
level $\alpha = 0.1$ and $\alpha = 0.01$, respectively, and exactly the cells which
violate the independence hypothesis are highlighted. For the arthritis data, these are in particular the 
cells in the last column that signal that there are significantly more
treated patients and fewer placebo patients with marked improvement than would be expected
under independence.

The significance levels $\alpha = 0.1$ and $\alpha = 0.01$ are chosen because this
leads to displays where fully colored cells are clearly significant ($p < 0.01$),
cells without color are clearly non-significant ($p > 0.1$), and
cells in between can be considered to be weakly significant ($0.01 \le p \le 0.1$).
Of course, users could choose any other set of significance levels they feel comfortable
with, e.g., only a single cut off at $\alpha = 0.05$ or three cut offs at $0.1$, $0.05$ and $0.01$
etc. Another option could be to use a continuous shading where the $p$ value corresponding
to a cell controls the interpolation between the neutral and the full color. However,
this typically results in too much color in the plot which in turn tends
to conceal the important cells and over-emphasize the unimportant ones. Hence,
a discrete shading with few colors is much easier to interpret.


\setkeys{Gin}{width=2\textwidth}
\begin{sidewaysfigure}[p]
\begin{center}
<<shadings,fig=TRUE,height=12,width=18,include=FALSE>>=
##                                       width=16
mymar <- c(1.5, 0.5, 0.5, 2.5)
grid.newpage()
pushViewport(viewport(layout = grid.layout(2, 3)))
pushViewport(viewport(layout.pos.row = 1, layout.pos.col = 1))
mosaic(art, newpage = FALSE, gp = shading_Friendly, margins = mymar,
  gp_args = list(eps = NULL, lty = 1))
popViewport()
pushViewport(viewport(layout.pos.row = 1, layout.pos.col = 2))
mosaic(art, newpage = FALSE, gp = shading_hsv, margins = mymar,
  gp_args = list(interpolate = art_max$qdist(c(0.9, 0.99)), p.value = art_max$p.value))
popViewport()
pushViewport(viewport(layout.pos.row = 1, layout.pos.col = 3))
mosaic(art, newpage = FALSE, gp = shading_hcl, margins = mymar,
  gp_args = list(interpolate = art_max$qdist(c(0.9, 0.99)), p.value = art_max$p.value))
popViewport()

pushViewport(viewport(layout.pos.row = 2, layout.pos.col = 1))
mosaic(pring, newpage = FALSE, gp = shading_Friendly, margins = mymar,
  gp_args = list(eps = NULL, lty = 1, interpolate = c(1, 1.5)))
popViewport()
pushViewport(viewport(layout.pos.row = 2, layout.pos.col = 2))
mosaic(pring, newpage = FALSE, gp = shading_hsv, margins = mymar,
  gp_args = list(interpolate = c(1, 1.5), p.value = pring_chisq$p.value))
popViewport()
pushViewport(viewport(layout.pos.row = 2, layout.pos.col = 3))
mosaic(pring, newpage = FALSE, gp = shading_hcl, margins = mymar,
  gp_args = list(interpolate = c(1, 1.5), p.value = pring_chisq$p.value))
popViewport(2)
@
%%\includegraphics[height=\textwidth,angle=90,keepaspectratio]{JCGS-shadings}
\includegraphics[width=.9\textwidth,keepaspectratio]{JCGS-shadings}
\caption{Upper row: Mosaic plot for the arthritis data with Friendly shading (left),
HSV maximum shading (middle), HCL maximum shading (right). Lower row: Mosaic
plot for the piston rings data with fixed user-defined cut offs 1 and 1.5 and 
Friendly shading (left), HSV sum-of-squares shading (middle), HCL sum-of-squares shading
(right).}
\label{fig:shadings}
\end{center}
\end{sidewaysfigure}
\setkeys{Gin}{width=\textwidth}

This maximum shading is already very flexible and combines visualization and inference.
However, it can only be applied when employing the maximum statistic because it is the only
aggregation functional $\lambda(\cdot)$ where a single large residual $|r_{ij}|$ exceeding
its critical value is equivalent
to a significant value of the whole test statistic $\lambda([r_{ij}])$.
%% `proof' for maximum shading
%% \footnote{This can easily be seen from the following consideration: To obtain a level $\alpha$ test, where 
%% any residual $|r_{ij}|$ exceeding the critical value $c_\alpha$ gives a significant test
%% result, the equation $\alpha = P(\mbox{any } |r_{ij}| > c_\alpha)$ must hold. This is equivalent
%% to $1 - \alpha = P(\mbox{all } |r_{ij}| \le c_\alpha) = P(\max_{i,j} |r_{ij}| \le c_\alpha)$.}
Typically, applying the maximum statistic is feasible and also appropriate for exploratory 
analysis, but it would be desirable to also have a residual-based shading that can incorporate
visualization of significance when the sum-of-squares statistic $X^2$ (or any other functional
$\lambda(\cdot)$) is used. For the reasons discussed above, it is not possible to achieve this by shading
individual cells differently but can only be realized by using different colors for the
whole table. As outlined before, colorfulness is intuitively matched with interestingness,
therefore a rather natural idea is to use the fully colored palette only when the corresponding
test is significant and to use a less colorful palette if not. For the HCL scheme, the
amount of color can conveniently be controlled by varying the maximum chroma value used. For the full
colors, the maximum chroma was set to $100$ as shown in Figure~\ref{fig:shadingHSVHCL} and 
is decreased to $20$ for the reduced-color palette. This palette still codes the absolute
size of the residuals by luminance (i.e., the amount of grey), uses the same neutral grey
for small `un-interesting' residuals, codes positive and negative residuals by different hues,
but gives less emphasis to the pattern by making the plot less colorful. A similar effect
can be obtained in the HSV space if the value is reduced from $100$ to $50$ for reduced-color 
palettes (see Figure~\ref{fig:shadingHSVHCL}). As for the full colors,
the dimensions used for creating this palette are confounded and hence the HCL scheme is clearly
preferable.

To see such a sum-of-squares shading in practice, we employ a data set on the number of piston
ring failures in three legs (north/center/south) in four different steam-driven compressors
at an Imperial Chemical Industries plant. The contingency table is given in \cite{vcd:Haberman:1973}, re-analyzed
by \cite{vcd:Everitt+Hothorn:2006} and displayed in the lower row of Figure~\ref{fig:shadings}.
Neither the sum-of-squares test ($X^2 = \Sexpr{stat(pring_chisq)}$, $p = \Sexpr{pval(pring_chisq)}$)
nor the maximum test ($M = \Sexpr{stat(pring_max)}$, $p = \Sexpr{pval(pring_max)}$) find
evidence for a departure from independence in the data (at the 5\% level). However, as argued
by \cite{vcd:Everitt+Hothorn:2006}, a closer look at the size of the residuals might be
interesting. To do so, we choose two fixed cut offs within the range of residuals, 1 and 1.5,
showing that more failures (than expected under independence) in the center leg and less failures
in the south leg were observed for compressor 1 and vice versa for compressor 4. This is
brought out clearly by all three shadings in the lower row of Figure~\ref{fig:shadings}. 
However, less emphasis is given to this pattern by the sum-of-squares shadings in the
middle and right panel because the reduced color palettes are used due to non-significance
of the associated test (at 5\% level). Comparing the HSV-based and HCL-based version
shows that the latter are less flashy and more balanced.

Other strategies for constructing palettes for general aggregation functionals $\lambda(\cdot)$
(including the sum of squares) that are similar in spirit to the maximum shading are conceivable.
Instead of using a reduced-color palette for non-significant tests, a no-color palette with
only a light grey could be employed. This could also be seen as always using cut offs
outside the range of residuals for non-significant tests. Analogously, for significant tests,
cut offs that are always inside the range of residuals could be chosen. The latter could
be determined by subject-matter knowledge, as a fraction of the associated critical value,
or as certain quantiles of the absolute residuals.



\section{Extensions} \label{sec:3way}

To introduce the new residual-based shadings without too much overhead in
Section~\ref{sec:shadings}, we have only considered the independence problem
in 2-way tables. In this section, generalizations of these ideas to independence
problems for multi-way tables are outlined. 

Mosaic displays have been emphasized in the literature to be an excellent means
of visualization for log-linear models \citep{vcd:Friendly:1999,vcd:Theus+Lauer:1999};
typical hypotheses of interest include complete, joint or conditional independence.
For all of these hypotheses, tables of estimated expected values and residuals
(again Pearson or deviance) can be computed and \cite{vcd:Friendly:1994,vcd:Friendly:1999}
shows that his residual-based  shading scheme can directly be applied to these more complex
independence models.
For inference, the most commonly used aggregation functional for the residuals
is again the sum of squares yielding the associated Pearson or likelihood
ratio statistic, respectively \citep{vcd:Agresti:2002}.

As these independence models for multi-way tables also provide the structure
required for the residual-based HCL shadings derived in Section~\ref{sec:shadings},
both the maximum shading and the sum-of-squares shading can straightforwardly be applied.
However, such independence models often additionally provide further structure that allows
decomposition of the overall model into smaller independence problems which can be exploited
both for choosing appropriate data-driven cut-offs in the shading and for selecting 
a suitable layout of mosaic or association plots. Specific strategies for the conditional
independence problem in 3-way tables are derived in the following.

Association plots are not commonly used for contingency tables with more than two 
margins, although there is nothing in the definition that would prevent application
in higher dimensions. However, as argued for the mosaic plots by \cite{vcd:Friendly:1999}
and \cite{vcd:Theus+Lauer:1999}, it becomes increasingly
important to choose a good layout as the number of variables grows.

\setkeys{Gin}{width=\textwidth}
\begin{figure}[b!]
\begin{center}
<<conditional_mosaic,fig=TRUE,height=5,width=9>>=
cotabplot(~ Smoking + Disease | Gender, data = alz, panel = alz_cotab)
@
\caption{Conditional mosaic plot with double maximum shading for conditional
independence of smoking and disease given gender.}
\label{fig:alz}
\end{center}
\end{figure}

How the structure of the independence problem can be exploited for 
selecting a suitable layout and shading for mosaic and association plots,
is exemplified with the conditional independence problem in 3-way tables.
For a table $[n_{ijk}]$ with underlying
theoretical probability distribution $[\pi_{ijk}]$, this can be formulated as
\begin{equation} \label{eq:H0ci}
H_0: \; \pi_{ij|k} \quad = \quad \pi_{i+|k} \pi_{+j|k}.
\end{equation}
where $\pi_{ij|k}$ are the conditional probabilities given the stratum $k$
with $k = 1, \dots, K$. Under the assumption of conditional independence,
we can again estimate expected frequencies $[\hat n_{ijk}]$ and the corresponding 
residuals $[r_{ijk}]$. To test the conditional independence hypothesis, usually
the sum-of-squares statistic is used
\begin{equation} \label{eq:sumchisq}
\sum_{i, j, k} r_{ijk}^2 \quad = \quad \sum_k X_k^2,
\end{equation}
which is simply the sum of the individual sum-of-squares statistics $X_k^2$ in each stratum $k$.

Alternatively, a maximum statistic similar to that from Equation~\ref{eq:MaxAbs}
can be constructed
\begin{equation} \label{eq:dmax}
\max_{i, j, k} |r_{ijk}| \quad = \quad \max_k M_k.
\end{equation}
As in the 2-way case, this allows for identification of the cells which are responsible
for the deviation from conditional independence (if any). If it is not so much of interest
in which \emph{cell} but only in which \emph{stratum} the deviation occurs, then
it would be natural to use 
\begin{equation} \label{eq:maxchisq}
\max_k \sum_{i,j} r_{ijk}^2 \quad = \quad \max_k X_k^2.
\end{equation}
Given a critical value for this statistic, all strata $k$ whose associated sum-of-squares
statistics $X_k^2$ exceed the critical value are in conflict with the hypothesis of 
conditional independence.

All these statistics are of type
\begin{equation} \label{eq:coindep_test}
\lambda_\mathrm{agg} (\lambda_\mathrm{indep}([r_{ijk}])),
\end{equation}
where $\lambda_\mathrm{indep}$ is a functional for assessing independence in stratum $k$
and $\lambda_\mathrm{agg}$ is a functional for aggregating over the $k = 1, \dots, K$ strata.
If the maximum is used for the latter, then identification of the strata responsible for the
non-independence is possible. If additionally $\lambda_\mathrm{indep}$ is the maximum,
the corresponding cells can also be identified. Hence, the double maximum
statistic from Equation~\ref{eq:dmax} is the only functional allowing for detection of
both the strata and the cells violating the conditional independence hypothesis.

However, the main purpose of the formulation of the different test statistics is not so much 
inference but their applicability to diagnostic plots via residual-based shadings. As already
discussed, it is possible for all aggregation functionals to simply use either
the full-color or the reduced-color shading for all cells in the contingency table---this
strategy would have to be used for the sum-of-squares statistic from Equation~\ref{eq:sumchisq}. If
$\lambda_\mathrm{agg}$ is the maximum as in Equation~\ref{eq:maxchisq},
then the full-color palette would only be used
in those strata in conflict with the hypothesis of conditional independence whereas the
reduced-color palette would be used for the remaining strata. Finally, if both $\lambda_\mathrm{agg}$
and $\lambda_\mathrm{indep}$ are the maximum, then the same strategy as in Section~\ref{sec:shadings}
can be pursued, i.e., only the full-color palette is used but with data-driven cut offs
derived from the distribution of the double maximum statistic from Equation~\ref{eq:dmax}.

To arrange the shaded rectangles of the association or the mosaic plot, respectively,
the most intuitive approach is to use the same conditioning in the display that
was also used for conditioning in the model. For this situation, \cite{vcd:Friendly:1999}
discusses a grouping similar to coplots \citep[conditioning plots, see][]{vcd:Cleveland:1993}
that lead to trellis graphics \citep{vcd:Becker+Cleveland+Shyu:1996}. Thus, a
natural visualization of such an independence model would be a trellis-like coplot
where each stratum $k$ could be visualized by an association or mosaic display.
This has also the advantage that only the conditional independence problem but
not the conditioning distribution over $k = 1, \dots, K$ is visualized which
could obscure departures from conditional independence if the number of observations
in each stratum $n_{++k}$ are very different.

\setkeys{Gin}{width=\textwidth}
\begin{figure}[t!]
\begin{center}
<<conditional_assoc,fig=TRUE,height=11,width=11>>=
cotabplot(~ Memory + Attitude | Age + Education, data = pun, panel = pun_cotab)
@
\caption{Conditional association plot with maximum sum-of-squares shading for conditional
independence of memory and attitude given age and education.}
\label{fig:pun}
\end{center}
\end{figure}

\setkeys{Gin}{width=\textwidth}
\begin{figure}[t!]
\begin{center}
<<conditional_mosaic2,fig=TRUE,height=11,width=11>>=
cotabplot(~ Memory + Attitude | Age + Education, data = pun, panel = pun_cotab2)
@
\caption{Conditional mosaic plot with maximum sum-of-squares shading for conditional
independence of memory and attitude given age and education.}
\label{fig:pun2}
\end{center}
\end{figure}

For illustration, a 3-way and a 4-way table are employed: The first is taken
from a case-control study of smoking and {A}lzheimer's disease published in
\cite{vcd:Salib+Hillier:1997} and re-analyzed using conditional inference techniques
in \cite{vcd:Hothorn+Hornik+VanDeWiel:2006}. It provides data on the smoking behaviour
(no, $<$10, 10--20, $>$20 cigarettes per day), disease status (Alzheimer's, other
dementias, other diagnoses) and gender. The question is whether smoking and disease 
status are conditionally independent given gender. All three statistics
suggested above find evidence for departure from independence: the sum-of-squares
statistic from Equation~\ref{eq:sumchisq} is $\sum_k X_k^2 = \Sexpr{stat(alz_sumchisq)}$
($p = \Sexpr{pval(alz_sumchisq)}$), the maximum sum-of-squares statistic from
Equation~\ref{eq:maxchisq} is $\max_k X_k^2 = \Sexpr{stat(alz_maxchisq)}$
($p = \Sexpr{pval(alz_maxchisq)}$), and the double maximum statistic from Equation~\ref{eq:dmax}
is $\max_k M_k = \Sexpr{stat(alz_dmax)}$ ($p = \Sexpr{pval(alz_dmax)}$).
The $p$ values are again computed by drawing $\Sexpr{nrep_char}$ samples from the corresponding
permutation distribution. The conditional mosaic plot in Figure~\ref{fig:alz}
shows clearly that the association of smoking and disease is present only in
the group of male patients. The double maximum shading employed allows for
identification of the male heavy smokers as the cells `responsible' for the dependence:
other dementias are more frequent and Alzheimer's disease less frequent in this group than expected
under independence. Interestingly, there seems to be another large residual for
the light smoker group ($<$10 cigarettes) and Alzheimer's disease---however, this
is only significant at 10\% and not at the 1\% level as the other two cells.

As a 4-way example, we use the punishment data \citep{vcd:andersen:1991} 
from a study of the Gallup Institute in Denmark in 1979 about
the attitude of a random sample of $1,456$ persons towards corporal
punishment of children. The contingency table comprises four margins:
memory of punishments as a child (yes/no), attitude as a binary variable
(approval of ``moderate'' punishment or ``no'' approval), highest level
of education (elementary/secondary/high), and age group (15--24, 25--39, $\ge$40 years).
It is of interest whether there is an association between memories of corporal punishments
as a child and attitude towards punishment of children as an adult, controlling
for age and education. Figure~\ref{fig:pun} shows a conditional association
plot of memory and attitude given age and education. This can be
interpreted as a diagnostic residual plot for the associated log-linear conditional
independence model. 
%FIXME: with mosaic%
Alternatively, a conditional mosaic plot as in Figure~\ref{fig:pun2} can be used for
visualizing the contingency table and its associated residuals from the conditional independence
model using the same shading. Both reveal
%FIXME: without mosaic% It shows 
an association between memories and attitude
for the lowest education group (first column) and highest age group (last row):
experienced violence seems to engender violence again as there are less adults
that disapprove punishment in the group with memories of punishments than expected
under independence. For the remaining four age-education groups, there seems to be
no association: all residuals of the conditional independence model are very close to
zero in these cells. All three tests agree again that there is significant
departure from conditional independence in this table: the sum-of-squares
statistic is $\sum_k X_k^2 = \Sexpr{stat(pun_sumchisq)}$ ($p = \Sexpr{pval(pun_sumchisq)}$),
the maximum sum-of-squares statistic is $\max_k X_k^2 = \Sexpr{stat(pun_maxchisq)}$
($p = \Sexpr{pval(pun_maxchisq)}$), and the double maximum statistic
is $\max_k M_k = \Sexpr{stat(pun_dmax)}$ ($p = \Sexpr{pval(pun_dmax)}$). The $\max_k X_k^2$
result is visualized by means of a maximum sum-of-squares shading in Figure~\ref{fig:pun}
with user-defined cut offs 1 and 2, chosen to be within the range of the residuals.
The full-color palette is used only for those strata associated with a
sum-of-squares statistic $X_k^2$ significant at (overall) 5\% level, the reduced-color
palette is used otherwise. This highlights that the dependence pattern is significant
only for the middle and high age group in the low education column. The other panels
in the first column and last row also show a similar dependence pattern, however, it is not
significant at 5\% level and hence graphically down-weighted by using reduced color.



\section{Conclusions} \label{sec:conclusions}

Various strategies for constructing residual-based shadings for visualizing
(conditional) independence in contingency tables via mosaic and association plots
are discussed. The shading
of \cite{vcd:Friendly:1994} is extended in two directions: the use of perceptually
uniform HCL colors and the combination of visualization and significance testing.
To achieve the former, a general guideline for constructing diverging palettes
in HCL space is introduced. The advantages of using this HCL shading scheme
instead of an HSV scheme are that the colors from this perceptually-based color space
provide uniform saturations over different hues and that the colorfulness in this
shading can be controlled independently from the other two dimensions.
%
To combine visualization and significance testing, two approaches are presented:
The first approach, based on the maximum statistic, always uses a fully colored palette but relies on
data-driven cut offs such that the presence of color is equivalent to significance of the
associated maximum test. The second approach, also applicable to other statistics such as
the sum of squares, uses pre-defined cut offs (e.g., $2$ and $4$) but
codes the result of the associated significance test by using full colors only if it
is significant and the same type of palette with a reduced amount of color otherwise.
%
Both strategies can not only be applied to the simple independence problem in 2-way
contingency tables, but also to arbitrary inpendence models fitted via log-linear models
in higher dimensions. In addition, it might be possible to exploit the structure of a given 
independence problem to achieve better visualizations which is illustrated
for the conditional independence problem.
%
All significance tests are carried out using a conditional inference approach
instead of relying on unconditional asymptotic results.

\section*{Acknowledgements}

We are thankful to Paul Murrell and Ross Ihaka---for providing tools, insights
and feedback that helped to derive the results presented in this paper---and to
two anonymous referees and editor Luke Tierney---for valuable comments and suggestions
that lead to a substantial improvement of the paper.

\clearpage

\section*{Computational Details}

The results in this paper were obtained using
\proglang{R}~\Sexpr{paste(R.Version()[6:7], collapse = ".")}
\citep[\mbox{\url{http://www.R-project.org/}}]{vcd:R:2006} and the packages
\pkg{vcd}~\Sexpr{packageDescription("vcd")$Version} \citep{vcd:Meyer+Zeileis+Hornik:2006b},
{\pkg{MASS}~\Sexpr{packageDescription("MASS")$Version}} \citep[see][]{vcd:Venables+Ripley:2002},
{\pkg{grid}~{\Sexpr{packageDescription("grid")$Version}}} \citep[see][]{vcd:Murrell:2002} and
{\pkg{colorspace}~{\Sexpr{packageDescription("colorspace")$Version}}} \citep{vcd:Ihaka:2004}.
A vignette that demonstrates how all empirical examples can exactly be reproduced
in \proglang{R} is provided in the package \pkg{vcd}, see
\code{vignette("residual-shadings", package = "vcd")}.

\bibliography{vcd}

\end{document}











%% deprecated stuff

\newpage

\begin{appendix}

\section{Replication of Results in R}

\begin{verbatim}
## random seed
rseed <- 1071

## load packages and data
library("vcd")
art <- xtabs(~ Treatment + Improved, data = Arthritis, subset = Sex == "Female")
data("pistonrings", package = "HSAUR")
data("alzheimer", package = "coin")
alz <- xtabs(~ smoking + disease + gender, data = alzheimer)
pun <- xtabs(Freq ~ memory + attitude + age + education, data = Punishment)


## Inference
## sum of squares
ss <- function(x) sum(x^2)
## X^2 (3)
set.seed(rseed)
coindep_test(art, n = 5000, indepfun = ss)
set.seed(rseed)
coindep_test(pistonrings, n = 5000, indepfun = ss)
## M (4)
set.seed(rseed)
art_max <- coindep_test(art, n = 5000)
set.seed(rseed)
coindep_test(pistonrings, n = 5000)

## sum X^2 (6)
set.seed(rseed)
coindep_test(alz, 3, n = 5000, indepfun = ss, aggfun = sum)
set.seed(rseed)
coindep_test(pun, 3:4, n = 5000, indepfun = ss, aggfun = sum)
## max M (7)
set.seed(rseed)
coindep_test(alz, 3, n = 5000)
set.seed(rseed)
coindep_test(pun, 3:4, n = 5000)
## max X^2 (8)
set.seed(rseed)
coindep_test(alz, 3, n = 5000, indepfun = ss)
set.seed(rseed)
coindep_test(pun, 3:4, n = 5000, indepfun = ss)


## Figure 1
mosaic(art)
assoc(art)

## Figure 3
mosaic(art, gp = shading_Friendly(lty = 1, eps = NULL))
mosaic(art, gp = shading_hsv, gp_args = list(
  interpolate = art_max$qdist(c(0.9, 0.99)), p.value = art_max$p.value))
set.seed(rseed)
mosaic(art, gp = shading_max, gp_args = list(n = 5000))

mosaic(pistonrings, gp = shading_Friendly(lty = 1, eps = NULL, interpolate = c(1, 1.5)))
mosaic(pistonrings, gp = shading_hsv, gp_args = list(interpolate = c(1, 1.5)))
mosaic(pistonrings, gp = shading_hcl, gp_args = list(interpolate = c(1, 1.5)))

## Figure 4
set.seed(rseed)
cotabplot(~ smoking + disease | gender, data = alz, panel = cotab_coindep, n = 5000)

## Figure 5
set.seed(rseed)
cotabplot(~ memory + attitude | age + education, data = pun, panel = cotab_coindep,
  n = 5000, type = "assoc", test = "maxchisq", interpolate = 1:2)

## Figure 6
set.seed(rseed)
cotabplot(~ memory + attitude | age + education, data = pun, panel = cotab_coindep,
  n = 5000, type = "mosaic", test = "maxchisq", interpolate = 1:2)
\end{verbatim}

\end{appendix}





%% UCB admissions
data("UCBAdmissions", package = "datasets")
ucb <- aperm(UCBAdmissions)

set.seed(myseed)
ucb_dmax <- coindep_test(ucb, "Dept", n = nrep)
set.seed(myseed)
ucb_maxchisq <- coindep_test(ucb, "Dept", n = nrep, indepfun = function(x) sum(x^2))
set.seed(myseed)
ucb_sumchisq <- coindep_test(ucb, "Dept", n = nrep, indepfun = function(x) sum(x^2), aggfun = sum)
set.seed(myseed)
ucb_cotab <- cotab_coindep(ucb, condvars = "Dept", type = "assoc", n = nrep, margins = c(3, 1, 1, 3))

\setkeys{Gin}{width=\textwidth}
\begin{figure}[htbp]
\begin{center}
<<conditional_assoc,fig=TRUE,echo=FALSE,height=6,width=9,eval=FALSE>>=
cotabplot(~ Gender + Admit | Dept, data = ucb, panel = ucb_cotab)
@
\caption{Conditional association plot for UCB admissions with double maximum shading.}
\label{fig:ucb}
\end{center}
\end{figure}



%% employment data
<<employment,eval=FALSE>>
## data
data("Employment")
emp <- aperm(Employment)
emp1 <- co_table(Employment, "LayoffCause")[["Replaced"]]

## plain
assoc(emp1)
mosaic(emp1)

## new shadings
mosaic(emp1, gp = shading_Friendly)
mosaic(emp1, gp = shading_max)

## conditional
mosaic(emp, expected = ~(EmploymentStatus+EmploymentLength)*LayoffCause)
cotabplot(emp, "LayoffCause", split_vertical = TRUE)
cotabplot(emp, panel = cotab_coindep, type = "assoc")
cotabplot(emp, "LayoffCause", panel = cotab_coindep, type = "assoc", split_vertical = TRUE)
@

%% Friendly shading in detail
\setkeys{Gin}{width=0.8\textwidth}
\begin{figure}[htbp]
\begin{center}
<<Friendly-hue,fig=TRUE,echo=FALSE,height=4.8,width=8,eval=FALSE>>
plot(0.5, 0.5, xlim = c(0, 1), ylim = c(0, 1), type = "n", axes = FALSE, xlab = "", ylab = "", yaxs = "i")
dummy <- 0:100/100
dummy.col <- hsv(dummy[-101] + 1/200, 1, 1)
rect(dummy[-101], 0.6, dummy[-1], 1, border = dummy.col, col = dummy.col)
rect(0, 0.6, 1, 1)
axis(3)
mtext("hue", line = 2, cex = 1.5)
text(1, 0.45, "saturation = 1\nvalue = 1", pos = 2, cex = 1.2)
lines(c(0.1, 0), c(0.3, 0.6), lty = 2)
lines(c(2/3, 2/3), c(0.3, 0.6), lty = 2)
rect(0, 0.1, 0.2, 0.3, col = hsv(0, 1, 1))
rect(2/3 - 0.1, 0.1, 2/3 + 0.1, 0.3, col = hsv(2/3, 1, 1))
text(0.1, 0.1, expression(r[ij] < 0), pos = 1, cex = 1.5)
text(2/3, 0.1, expression(r[ij] > 0), pos = 1, cex = 1.5)
@

<<Friendly-sat,fig=TRUE,echo=FALSE,height=4.8,width=8,eval=FALSE>>
plot(0.5, 0.5, xlim = c(0, 1), ylim = c(0, 1), type = "n", axes = FALSE, xlab = "", ylab = "", yaxs = "i")
dummy <- 0:100/100
dummy.col <- hsv(2/3, dummy[-101] + 1/200, 1)
rect(dummy[-101], 0.8, dummy[-1], 1, border = dummy.col, col = dummy.col)
dummy.col <- hsv(0, dummy[-101] + 1/200, 1)
rect(dummy[-101], 0.6, dummy[-1], 0.8, border = dummy.col, col = dummy.col)
rect(0, 0.8, 1, 1)
rect(0, 0.6, 1, 0.8)
axis(3)
mtext("saturation", line = 2, cex = 1.5)
mtext(c("h = 0", "h = 2/3"), side = 2, at = c(0.7, 0.9), las = 1, cex = 1.2)
text(0.8, 0.5, "value = 1", pos = 2, cex = 1.2)
lines(c(0.1, 0), c(0.3, 0.6), lty = 2)
lines(c(0.5, 0.5), c(0.3, 0.6), lty = 2)
lines(c(0.9, 1), c(0.3, 0.6), lty = 2)
rect(0, 0.2, 0.2, 0.3, col = hsv(2/3, 0, 1))
rect(0, 0.1, 0.2, 0.2, col = hsv(0, 0, 1))
rect(0.4, 0.2, 0.6, 0.3, col = hsv(2/3, 0.5, 1))
rect(0.4, 0.1, 0.6, 0.2, col = hsv(0, 0.5, 1))
rect(0.8, 0.2, 1, 0.3, col = hsv(2/3, 1, 1))
rect(0.8, 0.1, 1, 0.2, col = hsv(0, 1, 1))
text(0.1, 0.1, expression(abs(r[ij]) < 2), pos = 1, cex = 1.5)
text(0.5, 0.1, expression((2 < abs(r[ij])) < 4), pos = 1, cex = 1.5)
text(0.9, 0.1, expression(abs(r[ij]) > 4), pos = 1, cex = 1.5)
@

<<Friendly-val,fig=TRUE,echo=FALSE,height=4.8,width=8,eval=FALSE>>
plot(0.5, 0.5, xlim = c(0, 1), ylim = c(0, 1), type = "n", axes = FALSE, xlab = "", ylab = "", yaxs = "i")
dummy <- 0:100/100
dummy.col <- hsv(2/3, 1, dummy[-101] + 1/200)
rect(dummy[-101], 0.8, dummy[-1], 1, border = dummy.col, col = dummy.col)
dummy.col <- hsv(0, 1, dummy[-101] + 1/200)
rect(dummy[-101], 0.6, dummy[-1], 0.8, border = dummy.col, col = dummy.col)
rect(0, 0.8, 1, 1)
rect(0, 0.6, 1, 0.8)
axis(3)
mtext("value", line = 2, cex = 1.5)
mtext(c("h = 0", "h = 2/3"), side = 2, at = c(0.7, 0.9), las = 1, cex = 1.2)
text(0, 0.5, paste("saturation =", 1), pos = 4, cex = 1.2)
lines(c(0.85, 1), c(0.3, 0.6), lty = 2)
rect(0.7, 0.2, 0.8, 0.3, col = hsv(2/3, 0, 1))
rect(0.8, 0.2, 0.9, 0.3, col = hsv(2/3, 0.5, 1))
rect(0.9, 0.2, 1, 0.3, col = hsv(2/3, 1, 1))
rect(0.7, 0.1, 0.8, 0.2, col = hsv(0, 0, 1))
rect(0.8, 0.1, 0.9, 0.2, col = hsv(0, 0.5, 1))
rect(0.9, 0.1, 1, 0.2, col = hsv(0, 1, 1))
lines(c(0.5, 0.5), c(0.3, 0.6), lty = 2)
lines(c(0.85, 1), c(0.3, 0.6), lty = 2)
rect(0.35, 0.2, 0.45, 0.3, col = hsv(2/3, 0, 0.5))
rect(0.45, 0.2, 0.55, 0.3, col = hsv(2/3, 0.5, 0.5))
rect(0.55, 0.2, 0.65, 0.3, col = hsv(2/3, 1, 0.5))
rect(0.35, 0.1, 0.45, 0.2, col = hsv(0, 0, 0.5))
rect(0.45, 0.1, 0.55, 0.2, col = hsv(0, 0.5, 0.5))
rect(0.55, 0.1, 0.65, 0.2, col = hsv(0, 1, 0.5))
rect(0.7, 0.2, 0.8, 0.3, col = hsv(2/3, 0, 1))
rect(0.8, 0.2, 0.9, 0.3, col = hsv(2/3, 0.5, 1))
rect(0.9, 0.2, 1, 0.3, col = hsv(2/3, 1, 1))
rect(0.7, 0.1, 0.8, 0.2, col = hsv(0, 0, 1))
rect(0.8, 0.1, 0.9, 0.2, col = hsv(0, 0.5, 1))
rect(0.9, 0.1, 1, 0.2, col = hsv(0, 1, 1))
text(0.5, 0.1, "reduced color", pos = 1, cex = 1.5)
text(0.85, 0.1, "full color", pos = 1, cex = 1.5)
@

\caption{Extended Friendly shading in HSV space.}
\label{fig:Friendly-HSV}
\end{center}
\end{figure}


